name: Deploy to Databricks

# Trigger on push to main branch
on:
  push:
    branches:
      - main
  workflow_dispatch:  # Allow manual trigger from GitHub UI

# Environment variables (from GitHub Secrets)
env:
  DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
  DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

jobs:
  # ===========================
  # JOB 1: SYNC CODE TO DATABRICKS
  # ===========================
  sync-to-databricks:
    name: Sync Notebooks to Databricks Workspace
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout code from GitHub
      - name: Checkout code
        uses: actions/checkout@v4

      # Step 2: Setup Python
      - name: Setup Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # Step 3: Install Databricks CLI
      - name: Install Databricks CLI
        run: |
          pip install databricks-cli

      # Step 4: Configure Databricks CLI
      - name: Configure Databricks CLI
        run: |
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = $DATABRICKS_HOST" >> ~/.databrickscfg
          echo "token = $DATABRICKS_TOKEN" >> ~/.databrickscfg

      # Step 5: Create or update Databricks Repo
      - name: Sync code to Databricks Repos
        run: |
          # Try to update existing repo, create if doesn't exist
          REPO_PATH="/Repos/Production/azure-rag-heineken"

          # Check if repo exists
          if databricks repos get --path "$REPO_PATH" 2>/dev/null; then
            echo "Repo exists, updating..."
            databricks repos update --path "$REPO_PATH" --branch main
          else
            echo "Repo doesn't exist, creating..."
            databricks repos create \
              --url https://github.com/Matin0SH/azure-rag-heineken \
              --provider gitHub \
              --path "$REPO_PATH"
          fi

          echo "✅ Code synced to Databricks workspace at $REPO_PATH"

  # ===========================
  # JOB 2: POST-DEPLOYMENT VALIDATION
  # ===========================
  # NOTE: Terraform deployment skipped - run manually from local machine
  # Reason: Requires Azure Service Principal (admin permissions needed)

  validate-deployment:
    name: Validate Deployment
    runs-on: ubuntu-latest
    needs: sync-to-databricks

    steps:
      # Step 1: Checkout code
      - name: Checkout code
        uses: actions/checkout@v4

      # Step 2: Install Databricks CLI
      - name: Install Databricks CLI
        run: pip install databricks-cli

      # Step 3: Configure Databricks CLI
      - name: Configure Databricks CLI
        run: |
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = $DATABRICKS_HOST" >> ~/.databrickscfg
          echo "token = $DATABRICKS_TOKEN" >> ~/.databrickscfg

      # Step 4: Verify Databricks Repo exists
      - name: Verify Databricks Repo
        run: |
          REPO_PATH="/Repos/Production/azure-rag-heineken"
          if databricks repos get --path "$REPO_PATH"; then
            echo "✅ Databricks Repo verified at $REPO_PATH"
          else
            echo "❌ Databricks Repo not found"
            exit 1
          fi

      # Step 5: List Databricks jobs (verify Terraform created them)
      - name: Verify Databricks Jobs
        run: |
          echo "Listing Databricks jobs..."
          databricks jobs list --output JSON | jq '.jobs[] | {job_id, name: .settings.name}'
          echo "✅ Databricks jobs verified"
